# üíª Voice Assistant - Implementation Guide

## üìÅ Project Structure

```
f:\MiniProject\src\
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ VoiceAssistant/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VoiceAssistant.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VoiceButton.js
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ VoiceButton.css
‚îÇ   ‚îî‚îÄ‚îÄ ... (existing components)
‚îÇ
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ voiceService.js
‚îÇ
‚îú‚îÄ‚îÄ context/
‚îÇ   ‚îî‚îÄ‚îÄ VoiceContext.js
‚îÇ
‚îî‚îÄ‚îÄ locales/
    ‚îú‚îÄ‚îÄ voice-en.json
    ‚îú‚îÄ‚îÄ voice-kn.json
    ‚îî‚îÄ‚îÄ voice-hi.json
```

---

## üîß Step 1: Voice Service

Create `src/services/voiceService.js`:

```javascript
// Text-to-Speech
export const speak = (text, language = 'en-US') => {
  if (!('speechSynthesis' in window)) {
    console.error('Speech synthesis not supported');
    return;
  }

  window.speechSynthesis.cancel();
  const utterance = new SpeechSynthesisUtterance(text);
  
  const langMap = { en: 'en-US', kn: 'kn-IN', hi: 'hi-IN' };
  utterance.lang = langMap[language] || 'en-US';
  utterance.rate = 0.9;
  utterance.pitch = 1.0;
  utterance.volume = 1.0;

  window.speechSynthesis.speak(utterance);
};

// Speech-to-Text
export const listen = (language = 'en', callbacks = {}) => {
  if (!('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)) {
    console.error('Speech recognition not supported');
    return null;
  }

  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  const recognition = new SpeechRecognition();

  const langMap = { en: 'en-US', kn: 'kn-IN', hi: 'hi-IN' };
  recognition.lang = langMap[language] || 'en-US';
  recognition.continuous = false;
  recognition.interimResults = false;

  recognition.onresult = (event) => {
    const transcript = event.results[0][0].transcript;
    callbacks.onResult?.(transcript);
  };

  recognition.onerror = (event) => callbacks.onError?.(event.error);
  recognition.onend = () => callbacks.onEnd?.();

  recognition.start();
  return recognition;
};

export const stopListening = (recognition) => recognition?.stop();
export const stopSpeaking = () => window.speechSynthesis?.cancel();
```

---

## üéØ Step 2: Voice Context

Create `src/context/VoiceContext.js`:

```javascript
import React, { createContext, useState, useContext, useEffect } from 'react';
import { speak, listen, stopListening, stopSpeaking } from '../services/voiceService';

const VoiceContext = createContext();

export const VoiceProvider = ({ children }) => {
  const [voiceEnabled, setVoiceEnabled] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [currentRecognition, setCurrentRecognition] = useState(null);

  useEffect(() => {
    const saved = localStorage.getItem('voiceEnabled');
    if (saved) setVoiceEnabled(JSON.parse(saved));
  }, []);

  const toggleVoice = () => {
    const newState = !voiceEnabled;
    setVoiceEnabled(newState);
    localStorage.setItem('voiceEnabled', JSON.stringify(newState));
    
    if (newState) {
      speak("Voice assistant enabled", 'en');
    } else {
      stopSpeaking();
      if (currentRecognition) stopListening(currentRecognition);
    }
  };

  const speakText = (text, language) => {
    if (voiceEnabled) speak(text, language);
  };

  const startListening = (language, callbacks) => {
    if (voiceEnabled) {
      setIsListening(true);
      const recognition = listen(language, {
        ...callbacks,
        onEnd: () => {
          setIsListening(false);
          callbacks.onEnd?.();
        }
      });
      setCurrentRecognition(recognition);
      return recognition;
    }
  };

  return (
    <VoiceContext.Provider value={{
      voiceEnabled,
      toggleVoice,
      isListening,
      speakText,
      startListening
    }}>
      {children}
    </VoiceContext.Provider>
  );
};

export const useVoice = () => useContext(VoiceContext);
```

---

## üîò Step 3: Floating Voice Button

Create `src/components/VoiceAssistant/VoiceButton.js`:

```javascript
import React from 'react';
import { useVoice } from '../../context/VoiceContext';
import './VoiceButton.css';

const VoiceButton = ({ onCommand }) => {
  const { voiceEnabled, isListening, startListening } = useVoice();
  const { language } = useApp();

  if (!voiceEnabled) return null;

  const handleClick = () => {
    startListening(language, {
      onResult: (text) => {
        console.log('Voice input:', text);
        onCommand?.(text);
      },
      onError: (error) => console.error('Voice error:', error)
    });
  };

  return (
    <button 
      className={`floating-voice-btn ${isListening ? 'listening' : ''}`}
      onClick={handleClick}
      aria-label="Voice command"
    >
      <i className="fas fa-microphone"></i>
      {isListening && <span className="pulse-ring"></span>}
    </button>
  );
};

export default VoiceButton;
```

Create `src/components/VoiceAssistant/VoiceButton.css`:

```css
.floating-voice-btn {
  position: fixed;
  bottom: 30px;
  right: 30px;
  width: 60px;
  height: 60px;
  border-radius: 50%;
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  border: none;
  box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
  cursor: pointer;
  font-size: 1.5rem;
  z-index: 1000;
  transition: all 0.3s ease;
}

.floating-voice-btn:hover {
  transform: scale(1.1);
}

.floating-voice-btn.listening {
  background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
  animation: pulse 1.5s infinite;
}

.pulse-ring {
  position: absolute;
  width: 70px;
  height: 70px;
  border: 3px solid #f5576c;
  border-radius: 50%;
  top: -5px;
  left: -5px;
  animation: pulseRing 1.5s infinite;
}

@keyframes pulse {
  0%, 100% { transform: scale(1); }
  50% { transform: scale(1.05); }
}

@keyframes pulseRing {
  0% { transform: scale(1); opacity: 1; }
  100% { transform: scale(1.3); opacity: 0; }
}
```

---

## üè† Step 4: Update App.js

```javascript
import { VoiceProvider } from './context/VoiceContext';
import VoiceButton from './components/VoiceAssistant/VoiceButton';

function App() {
  return (
    <AppProvider>
      <VoiceProvider>
        <Router>
          <div className="app-wrapper">
            <Routes>
              {/* ... existing routes ... */}
            </Routes>
            <VoiceButton /> {/* Add floating button */}
            <Footer />
          </div>
        </Router>
      </VoiceProvider>
    </AppProvider>
  );
}
```

---

## üè† Step 5: Update Home.js

Add voice toggle to header:

```javascript
import { useVoice } from '../context/VoiceContext';

const Home = () => {
  const { voiceEnabled, toggleVoice, speakText } = useVoice();
  const { language } = useApp();

  useEffect(() => {
    if (voiceEnabled) {
      speakText("Welcome to BMTC Smart Transit", language);
    }
  }, [voiceEnabled]);

  return (
    <div>
      <header className="main-header">
        <div className="header-actions">
          <button 
            className={`header-btn ${voiceEnabled ? 'voice-active' : ''}`}
            onClick={toggleVoice}
          >
            <i className={`fas ${voiceEnabled ? 'fa-microphone' : 'fa-microphone-slash'}`}></i>
            <span>{voiceEnabled ? 'Voice On' : 'Voice Off'}</span>
          </button>
          {/* ... other buttons ... */}
        </div>
      </header>
      {/* ... rest of component ... */}
    </div>
  );
};
```

---

## üöå Step 6: Add Voice to TrackBus

```javascript
import { useVoice } from '../context/VoiceContext';

const TrackBus = () => {
  const { voiceEnabled, speakText, startListening } = useVoice();
  const { language } = useApp();
  const [busNumber, setBusNumber] = useState('');

  const handleVoiceInput = () => {
    speakText("Please say the bus number", language);
    
    startListening(language, {
      onResult: (text) => {
        const extractedNumber = extractBusNumber(text);
        if (extractedNumber) {
          setBusNumber(extractedNumber);
          speakText(`Tracking bus ${extractedNumber}`, language);
          handleSearch(extractedNumber);
        }
      }
    });
  };

  const extractBusNumber = (text) => {
    // Extract bus number from speech (e.g., "three three five E" ‚Üí "335E")
    const normalized = text.toLowerCase();
    // Add number mapping logic here
    return normalized.match(/\d+[a-z]*/i)?.[0] || text;
  };

  return (
    <div>
      <input
        value={busNumber}
        onChange={(e) => setBusNumber(e.target.value)}
        placeholder="Enter bus number"
      />
      {voiceEnabled && (
        <button onClick={handleVoiceInput}>
          <i className="fas fa-microphone"></i> Voice Input
        </button>
      )}
      {/* ... rest of component ... */}
    </div>
  );
};
```

---

## üó∫Ô∏è Step 7: Voice Prompts JSON

Create `src/locales/voice-en.json`:

```json
{
  "welcome": "Welcome to BMTC Smart Transit",
  "selectLanguage": "Please say your preferred language",
  "trackBus": "Please say the bus number",
  "journeyOrigin": "Say your origin stop",
  "journeyDestination": "Say your destination",
  "crowdPrediction": "Say the bus number for crowd prediction",
  "fareFrom": "Say your starting point",
  "fareTo": "Say your destination",
  "searchComplete": "Search complete. {{count}} results found",
  "busArriving": "Bus {{number}} arriving in {{minutes}} minutes",
  "highCrowd": "Warning: High crowd level on this bus",
  "errorRetry": "Sorry, please try again",
  "unknownCommand": "I didn't understand. Please repeat"
}
```

Create `src/locales/voice-kn.json`:

```json
{
  "welcome": "‡≤¨‡≤ø‡≤é‡≤Æ‡≥ç‚Äå‡≤ü‡≤ø‡≤∏‡≤ø ‡≤∏‡≥ç‡≤Æ‡≤æ‡≤∞‡≥ç‡≤ü‡≥ç ‡≤ü‡≥ç‡≤∞‡≤æ‡≤®‡≥ç‡≤∏‡≤ø‡≤ü‡≥ç‚Äå‡≤ó‡≥Ü ‡≤∏‡≥ç‡≤µ‡≤æ‡≤ó‡≤§",
  "selectLanguage": "‡≤¶‡≤Ø‡≤µ‡≤ø‡≤ü‡≥ç‡≤ü‡≥Å ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤≠‡≤æ‡≤∑‡≥Ü ‡≤π‡≥á‡≤≥‡≤ø",
  "trackBus": "‡≤¨‡≤∏‡≥ç ‡≤∏‡≤Ç‡≤ñ‡≥ç‡≤Ø‡≥Ü ‡≤π‡≥á‡≤≥‡≤ø",
  "journeyOrigin": "‡≤Æ‡≥Ç‡≤≤ ‡≤®‡≤ø‡≤≤‡≥ç‡≤¶‡≤æ‡≤£ ‡≤π‡≥á‡≤≥‡≤ø",
  "journeyDestination": "‡≤ó‡≤Æ‡≥ç‡≤Ø‡≤∏‡≥ç‡≤•‡≤æ‡≤® ‡≤π‡≥á‡≤≥‡≤ø"
}
```

Create `src/locales/voice-hi.json`:

```json
{
  "welcome": "‡§¨‡•Ä‡§è‡§Æ‡§ü‡•Ä‡§∏‡•Ä ‡§∏‡•ç‡§Æ‡§æ‡§∞‡•ç‡§ü ‡§ü‡•ç‡§∞‡§æ‡§Ç‡§ú‡§ø‡§ü ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à",
  "selectLanguage": "‡§ï‡•É‡§™‡§Ø‡§æ ‡§Ö‡§™‡§®‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§¨‡•ã‡§≤‡•á‡§Ç",
  "trackBus": "‡§¨‡§∏ ‡§®‡§Ç‡§¨‡§∞ ‡§¨‡•ã‡§≤‡•á‡§Ç",
  "journeyOrigin": "‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠‡§ø‡§ï ‡§∏‡•ç‡§ü‡•â‡§™ ‡§¨‡•ã‡§≤‡•á‡§Ç",
  "journeyDestination": "‡§ó‡§Ç‡§§‡§µ‡•ç‡§Ø ‡§¨‡•ã‡§≤‡•á‡§Ç"
}
```

---

## üß™ Step 8: Testing

Create test file `src/components/VoiceAssistant/VoiceTest.js`:

```javascript
import React from 'react';
import { useVoice } from '../../context/VoiceContext';

const VoiceTest = () => {
  const { speakText, startListening } = useVoice();

  const testTTS = (lang) => {
    const messages = {
      en: "Hello, testing English",
      kn: "‡≤®‡≤Æ‡≤∏‡≥ç‡≤ï‡≤æ‡≤∞, ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤™‡≤∞‡≥Ä‡≤ï‡≥ç‡≤∑‡≥Ü",
      hi: "‡§®‡§Æ‡§∏‡•ç‡§§‡•á, ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§™‡§∞‡•Ä‡§ï‡•ç‡§∑‡§£"
    };
    speakText(messages[lang], lang);
  };

  const testSTT = (lang) => {
    startListening(lang, {
      onResult: (text) => alert(`Recognized: ${text}`),
      onError: (error) => alert(`Error: ${error}`)
    });
  };

  return (
    <div style={{padding: '20px'}}>
      <h2>Voice Assistant Test</h2>
      
      <h3>Text-to-Speech</h3>
      <button onClick={() => testTTS('en')}>Test English</button>
      <button onClick={() => testTTS('kn')}>Test Kannada</button>
      <button onClick={() => testTTS('hi')}>Test Hindi</button>
      
      <h3>Speech-to-Text</h3>
      <button onClick={() => testSTT('en')}>Listen English</button>
      <button onClick={() => testSTT('kn')}>Listen Kannada</button>
      <button onClick={() => testSTT('hi')}>Listen Hindi</button>
    </div>
  );
};

export default VoiceTest;
```

---

## ‚úÖ Checklist

- [ ] Install dependencies (none needed for Web Speech API!)
- [ ] Create voiceService.js
- [ ] Create VoiceContext.js
- [ ] Update App.js with VoiceProvider
- [ ] Add VoiceButton component
- [ ] Add voice toggle to Home
- [ ] Add voice input to TrackBus
- [ ] Create voice prompt JSON files
- [ ] Test TTS in all 3 languages
- [ ] Test STT in all 3 languages
- [ ] Test on different browsers

---

## üåê Browser Support

| Browser | TTS | STT | Notes |
|---------|-----|-----|-------|
| Chrome | ‚úÖ | ‚úÖ | Best support |
| Edge | ‚úÖ | ‚úÖ | Full support |
| Firefox | ‚úÖ | ‚ùå | TTS only |
| Safari | ‚úÖ | ‚ö†Ô∏è | Limited STT |

---

## üöÄ Quick Start

```bash
# No installation needed! Web Speech API is built-in

# Just add the files and test:
cd f:\MiniProject
npm start

# Navigate to home page
# Click "Voice Off" ‚Üí "Voice On"
# Click floating mic button
# Say "Track bus three three five E"
```

---

**Implementation Time:** 1-2 days for basic version

**Next:** See VOICE_TESTING_GUIDE.md for comprehensive testing procedures
